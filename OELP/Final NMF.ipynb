{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sasidharreddy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "22827\n",
      "16973\n",
      "1160\n",
      "2250\n",
      "9654\n",
      "52884\n",
      "[[0.         0.         0.00202055 ... 0.         0.         0.00873257]\n",
      " [0.06357881 0.         0.         ... 0.         0.30333325 0.02145271]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.06972398 0.         0.         ... 0.01738057 0.         0.        ]\n",
      " [0.         0.19868768 0.         ... 0.         0.         0.01494043]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.89706603e-02 0.00000000e+00]\n",
      " [5.15472588e+00 1.83858374e-01 0.00000000e+00 ... 9.32464351e-04\n",
      "  1.72935368e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.69561966e-02 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 3.35856136e-02 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.89414769e-02 1.46896850e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df = pd.read_csv('/home/sasidharreddy/study/OELP/data.csv', delimiter=',')\n",
    "df_key=pd.read_csv('/home/sasidharreddy/study/OELP/keywords.csv', delimiter='\\t')\n",
    "name=[]\n",
    "genres=[]\n",
    "story=[]\n",
    "rating=[]\n",
    "directors=[]\n",
    "pop_of_directors=[]\n",
    "cast=[]\n",
    "pop_of_cast=[]\n",
    "for i in df['Name']:\n",
    "    mve_list = ast.literal_eval(i)\n",
    "    name.append(mve_list[0])\n",
    "df['story'] = df['story'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stopwords.words('english')]))\n",
    "for i in df['genres']:\n",
    "    genres_list = ast.literal_eval(i)\n",
    "    genres.append(genres_list)\n",
    "for i in df['story']:\n",
    "    storyline=ast.literal_eval(i)\n",
    "    story.append(storyline[0].split())\n",
    "for i in df['rating']:\n",
    "    rating_list=ast.literal_eval(i)\n",
    "    rating.append(rating_list)\n",
    "\n",
    "d1={}\n",
    "cas,rank1=[],[]\n",
    "for i in df['cast']:\n",
    "    i=ast.literal_eval(i)\n",
    "    for j in i:\n",
    "        cas.append(j)\n",
    "for i in df['popularity of cast']:\n",
    "    i=ast.literal_eval(i)\n",
    "    for j in i:\n",
    "        if j is None:\n",
    "            j=5000\n",
    "        rank1.append(j)\n",
    "for i in range(len(cas)):\n",
    "    d1[cas[i]] = rank1[i]\n",
    "\n",
    "C = []                             # M is the matrix where each row represents each movie and column represents each unique keyword\n",
    "for i in df['cast']:\n",
    "    x = eval(i)\n",
    "    l = []\n",
    "    for j in d1.keys():\n",
    "        if(j in x):\n",
    "            if(int(d1[j])==0):\n",
    "                l.append(0.09)\n",
    "            else:\n",
    "                l.append(1-(int(d1[j])/11000))\n",
    "        else:\n",
    "            l.append(0)\n",
    "    C.append(l)\n",
    "\n",
    "d={}\n",
    "dir,rank=[],[]\n",
    "for i in df['directors']:\n",
    "    i=ast.literal_eval(i)\n",
    "    for j in i:\n",
    "        dir.append(j)\n",
    "for i in df['popularity of director']:\n",
    "    i=ast.literal_eval(i)\n",
    "    for j in i:\n",
    "        rank.append(j)\n",
    "for i in range(len(dir)):\n",
    "    d[dir[i]] = rank[i]\n",
    "\n",
    "R = []                             # M is the matrix where each row represents each movie and column represents each unique keyword\n",
    "for i in df['directors']:\n",
    "    x = eval(i)\n",
    "    l = []\n",
    "    for j in d.keys():\n",
    "        if(j in x):\n",
    "            if(int(d[j])==0):\n",
    "                l.append(0.09)\n",
    "            else:\n",
    "                l.append(1-(int(d[j])/11000))\n",
    "        else:\n",
    "            l.append(0)\n",
    "    R.append(l)\n",
    "s = set()                           # set of all unique keywords\n",
    "for i in df_key['k_h']:\n",
    "    x = eval(i)\n",
    "    for j in x.keys():\n",
    "        s.add(j)                             \n",
    "M = []                             # M is the matrix where each row represents each movie and column represents each unique keyword\n",
    "for i in df_key['k_h']:\n",
    "    x = eval(i)\n",
    "    l = []\n",
    "    for j in s:\n",
    "        if(j in x.keys()):\n",
    "            if(x[j]==0):\n",
    "                l.append(0.5)\n",
    "            else:\n",
    "                l.append(int(x[j]))\n",
    "        else:\n",
    "            l.append(0)\n",
    "    M.append(l)\n",
    "\n",
    "d2={}\n",
    "writ,rank2=[],[]\n",
    "for i in df['writers']:\n",
    "    i=ast.literal_eval(i)\n",
    "    for j in i:\n",
    "        writ.append(j)\n",
    "for i in df['popularity of writer']:\n",
    "    i=ast.literal_eval(i)\n",
    "    for j in i:\n",
    "        if j is None:\n",
    "            j=5000\n",
    "        rank2.append(j)\n",
    "for i in range(len(writ)):\n",
    "    d2[writ[i]] = rank2[i]\n",
    "\n",
    "W = []                             # M is the matrix where each row represents each movie and column represents each unique keyword\n",
    "for i in df['writers']:\n",
    "    x = eval(i)\n",
    "    l = []\n",
    "    for j in d2.keys():\n",
    "        if(j in x):\n",
    "            if(int(d2[j])==0):\n",
    "                l.append(0.09)\n",
    "            else:\n",
    "                l.append(1-(int(d2[j])/11000))\n",
    "        else:\n",
    "            l.append(0)\n",
    "    W.append(l)\n",
    "\n",
    "unique_genres = np.unique([genre for sublist in genres for genre in sublist])\n",
    "unique_story=np.unique([sto for sublist in story for sto in sublist])\n",
    "\n",
    "genre_matrix = [[1 if word in sublist else 0 for word in unique_genres] for sublist in genres]\n",
    "key_word_matrix = np.array(M)\n",
    "cast_matrix=np.array(C)\n",
    "director_matrix=np.array(R)\n",
    "writer_matrix=np.array(W)\n",
    "story_matrix=[[1 if word in sublist else 0 for word in unique_story] for sublist in story]\n",
    "print(len(genre_matrix[0]))\n",
    "print(len(key_word_matrix[0]))\n",
    "print(len(cast_matrix[0]))\n",
    "print(len(director_matrix[0]))\n",
    "print(len(writer_matrix[0]))\n",
    "print(len(story_matrix[0]))\n",
    "#normalizing the matrices\n",
    "def normalize_matrix(matrix, new_min, new_max):\n",
    "    min_val = np.min(matrix)\n",
    "    max_val = np.max(matrix)\n",
    "    matrix_range = max_val - min_val\n",
    "\n",
    "    normalized_matrix = (matrix - min_val) / matrix_range * (new_max - new_min) + new_min\n",
    "    return normalized_matrix\n",
    "\n",
    "\n",
    "genre_normalized_matrix = normalize_matrix(genre_matrix, 0, 1)\n",
    "key_words_normalized_matrix = normalize_matrix(key_word_matrix, 0, 1)\n",
    "cast_genre_normalized_matrix = normalize_matrix(cast_matrix, 0, 1)\n",
    "director_normalized_matrix = normalize_matrix(director_matrix, 0, 1)\n",
    "writer_normalized_matrix = normalize_matrix(writer_matrix, 0, 1)\n",
    "story_normalized_matrix = normalize_matrix(story_matrix, 0, 1)\n",
    "\n",
    "final_matrix=np.hstack((genre_normalized_matrix,key_words_normalized_matrix,cast_genre_normalized_matrix,director_normalized_matrix,writer_normalized_matrix,story_normalized_matrix))\n",
    "print(len(final_matrix[0]))\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "# Sample movie-feature matrix (replace this with your actual data)\n",
    "movie_feature_matrix = np.array(final_matrix)\n",
    "\n",
    "def nmf_reduction(M, k):\n",
    "    model = NMF(n_components=k)\n",
    "    W = model.fit_transform(M)\n",
    "    H = model.components_\n",
    "    return W,H\n",
    "w,h = nmf_reduction(movie_feature_matrix,44)\n",
    "reconstructed_matrix = np.dot(w,h)\n",
    "print(w)\n",
    "print(h)\n",
    "cos_sim = cosine_similarity(reconstructed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input movie is The Nun II\n",
      "1-Jeepers Creepers Reborn\n",
      "2-Annabelle Comes Home\n",
      "3-The Curse of the Weeping Woman\n",
      "4-The Visit\n",
      "5-Influencer\n",
      "6-Slender Man\n",
      "7-Sick\n",
      "8-The Conjuring 2\n",
      "9-The Conjuring 3\n",
      "10-Truth or Dare\n",
      "11-Eight for Silver\n",
      "12-Us\n",
      "13-In the Earth\n",
      "14-The Night House\n",
      "15-The Black Phone\n",
      "16-The Ritual\n",
      "17-There's Someone Inside Your House\n",
      "18-Smile\n",
      "19-Annabelle: Creation\n",
      "20-Nefarious\n"
     ]
    }
   ],
   "source": [
    "movie_name = 'The Nun II'\n",
    "try:\n",
    "    index = name.index(movie_name)\n",
    "    print(f\"The input movie is {movie_name}\")\n",
    "except ValueError:\n",
    "    print(f\"{movie_name} is not present in the list.\")\n",
    "\n",
    "import numpy as np\n",
    "# Assuming you have an array named 'your_array'\n",
    "max_array=np.array(cos_sim[index])\n",
    "\n",
    "# Get the indices of the 11 maximum values\n",
    "max_indices = np.argsort(max_array)[:-22:-1]\n",
    "max_indices=max_indices[1:]\n",
    "# Print the indices\n",
    "\n",
    "inde=0\n",
    "for i in max_indices:\n",
    "    inde=inde+1\n",
    "    print(f'{inde}-{name[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
