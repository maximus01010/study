{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Rough House\n",
      "{'title': 'The Rough House', 'director': {\"Roscoe 'Fatty' Arbuckle\": '10000', 'Buster Keaton': '10000'}, 'writer': {\"Roscoe 'Fatty' Arbuckle\": '10000', 'Buster Keaton': '10000', 'Joseph Anthony Roach': '10000'}, 'genres': ['Comedy', 'Short'], 'cast': [\"Roscoe 'Fatty' Arbuckle\", 'Al St. John', 'Buster Keaton', 'Alice Lake', 'Agnes Neilson', 'Glen Cavender', 'Josephine Stevens'], 'storyline': 'Roscoe, his wife and his mother-in-law run a seaside resort. Buster plays a gardener who puts out a fire started by Roscoe, then a delivery boy who fights with the cook St. John, then a cop.', 'avg_rating': '5.6', 'keywords': {'1910s': '0', '1900s': '0', 'newlywed': '0', 'mother': '0', 'mother in law': '0', 'newlywed couple': '0', 'bed': '0', 'bedroom': '0', 'falling asleep': '0', 'set fire': '0', 'blaze': '0', 'fire': '0', 'disaster': '0', 'gardener': '0', 'garden hose': '0', 'hose': '0', 'delivery': '0', 'delivery boy': '0', 'maid': '0', 'cook': '0', 'having a crush': '0', 'dough': '0', 'kitchen': '0', 'dinner': '0', 'preparation': '0', 'dinner party': '0', 'party': '0', 'guest': '0', 'visitor': '0', 'burglar': '0', 'necklace': '0', 'pearl necklace': '0', 'plainclothes officer': '0', 'pistol': '0', 'gunfire': '0', 'chase': '0', 'constable': '0', 'fence': '0', 'recruit': '0', 'nuptial': '0', 'carelessness': '0', 'happy end': '0', 'happy ending': '0', 'cigarette smoking': '0', 'husband wife relationship': '0', 'theft': '0', 'wetness': '0', 'male police officer': '0', 'police': '0', 'smoking in bed': '0'}}\n",
      "The Three Stooges \n",
      "Trans-Europ-Express \n",
      "{'title': 'Trans-Europ-Express', 'director': {'Alain Robbe-Grillet': '10000'}, 'writer': {'Alain Robbe-Grillet': '10000'}, 'genres': ['Comedy', 'Drama', 'Mystery'], 'cast': ['Jean-Louis Trintignant', 'Marie-France Pisier', 'Christian Barbier', 'Raoul Guylad', 'Henri Lambert', 'Paul Louyet', 'Charles Millot', 'Rezy Norbert', 'Gérard Palaprat', 'Catherine Robbe-Grillet', 'Salkin', 'Ariane Sapriel', 'Prima Symphony', 'Clotilde Vanesco', 'Nadine Verdier', 'Virginie Vignon', 'Daniel Emilfork', 'Jérôme Lindon', 'Ivo Pauwels', 'Alain Robbe-Grillet'], 'storyline': 'A movie producer, director and assistant take the Trans-Europ-Express from Paris to Antwerp. They get the idea for a movie about a drug smuggler on their train and visualize it while taping the script.', 'avg_rating': '7.1', 'keywords': {'sadomasochism': '3', 'train': '2', 'woman wears a bra and panties': '1', 'bondage': '1', 'sexuality': '1', 'nudity': '1', 'tied up': '1', 'female topless nudity': '1', 'female buttocks': '1', 'female nudity': '1', 'white bra and panties': '1', 'hotel room': '1', 'lust': '1', 'sex scene': '1', 'rape': '1', 'reference to crazy horse paris': '0', 'france': '0', 'murder': '0', 'strangulation': '0', 'director': '0', 'film within a film': '0', 'surrealism': '0', 'drug smuggling': '0'}}\n",
      "Yogi's Ark Lark\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import DictWriter\n",
    "\n",
    "def fetch(url):\n",
    "    try:\n",
    "        src = requests.get(url)\n",
    "        data = BeautifulSoup(src.text,'html.parser')\n",
    "        return data\n",
    "    except:\n",
    "        return None\n",
    "def fetch1(url):\n",
    "    try:\n",
    "        user_agent_list = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36',\n",
    "    'Mozilla/5.0 (iPhone; CPU iPhone OS 14_4_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Mobile/15E148 Safari/604.1',\n",
    "    'Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1)',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36 Edg/87.0.664.75',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.18363',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.82 Safari/537.36'\n",
    "]\n",
    "        html_text = requests.get(url, headers={'User-Agent': random.choice(user_agent_list)})\n",
    "        soup=BeautifulSoup(html_text.text,'lxml')\n",
    "        return soup\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def fetch_403(url):\n",
    "    try:\n",
    "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'}\n",
    "        src = requests.get(url,headers=headers)\n",
    "        data = BeautifulSoup(src.text,'html.parser')\n",
    "        return data\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def extract(url):\n",
    "    d = {}\n",
    "    try:\n",
    "        url1 = url+\"fullcredits\"\n",
    "        data1 = fetch(url1)\n",
    "        d['title'] = data1.h3.a.text\n",
    "        d['director'] = []\n",
    "        d['writer'] = []\n",
    "        try:\n",
    "            x = data1.find_all('table',class_='simpleTable simpleCreditsTable')\n",
    "            directors = x[0].tbody.find_all('tr')\n",
    "            y = {}\n",
    "            for i in directors:\n",
    "                for j in i.find_all('td',class_='name'):\n",
    "                    dir ='https://www.imdb.com'+j.a['href']\n",
    "                    #print(dir)\n",
    "                    z = fetch_403(dir)\n",
    "                    z = z.find('span',class_='sc-d462a8ef-6 gdrbUr starmeter-current-rank').text\n",
    "                    if(z=='See rank'):\n",
    "                        z = '10000'\n",
    "                    y[j.a.text.replace('\\n','')[1:]] = z\n",
    "                #print(y)\n",
    "                d['director'] = y\n",
    "        except:\n",
    "            d['director'] = []\n",
    "        try:\n",
    "            writers = x[1].tbody.find_all('tr')\n",
    "            y = {}\n",
    "            for i in writers:\n",
    "                for j in i.find_all('td',class_='name'):\n",
    "                    wri = 'https://www.imdb.com'+j.a['href']\n",
    "                    z = fetch_403(wri)\n",
    "                    z = z.find('span',class_='sc-d462a8ef-6 gdrbUr starmeter-current-rank').text\n",
    "                    if(z=='See rank'):\n",
    "                        z = '10000'\n",
    "                    y[j.a.text.replace('\\n','')[1:]] = z\n",
    "                #print(y)\n",
    "                d['writer'] = y\n",
    "        except:\n",
    "            d['writer'] = []\n",
    "\n",
    "        d['genres']=[]\n",
    "        data_genres=fetch1(url)\n",
    "        genres1=data_genres.find('div',class_='ipc-chip-list__scroller')\n",
    "        if genres1:\n",
    "            genres=genres1.find_all('a',class_='ipc-chip ipc-chip--on-baseAlt')\n",
    "            for genre in genres:\n",
    "                if genre:\n",
    "                    genre=genre.text\n",
    "                    d['genres'].append(genre)\n",
    "                    \n",
    "        d['cast'] = []\n",
    "        for i in data1.find('table',class_='cast_list').find_all('tr')[1:]:\n",
    "            try:\n",
    "                d['cast'].append(i.a.img['title'])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "\n",
    "\n",
    "        d['storyline'] = []\n",
    "        url4 = url+'plotsummary'\n",
    "        try:\n",
    "            data4 = fetch_403(url4)\n",
    "            data4 = data4.find('div',class_='ipc-html-content-inner-div').text\n",
    "            d['storyline'] = data4\n",
    "        except:\n",
    "            d['storyline'] = []\n",
    "        url5 = url+'ratings'\n",
    "        try:\n",
    "            data5 = fetch_403(url5)\n",
    "            d['avg_rating'] = data5.find('span',class_=\"sc-5931bdee-1 gVydpF\").text\n",
    "        except:\n",
    "            d['avg_rating'] = []\n",
    "        return d\n",
    "    except:\n",
    "        return d\n",
    "    \n",
    "\n",
    "def load(d):\n",
    "    try:\n",
    "        with open('/home/sasidharreddy/study/OELP/moremovies/maam.csv', 'a',newline='') as f_object:\n",
    "            dictwriter_object = DictWriter(f_object,fieldnames=d.keys(),delimiter='\\t')\n",
    "            dictwriter_object.writerow(d)\n",
    "            f_object.close()\n",
    "    except:\n",
    "        return\n",
    "\n",
    "d = pd.read_json('/home/sasidharreddy/study/OELP/moremovies/test.json',orient='index')\n",
    "\n",
    "for i in d[0].keys():\n",
    "    i = i.replace('_',' ')\n",
    "    print(i)\n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "        url = 'https://www.imdb.com/'\n",
    "        driver.get(url)\n",
    "        search = driver.find_element(By.ID,'suggestion-search')\n",
    "        submit = driver.find_element(By.ID,'suggestion-search-button')\n",
    "        search.send_keys(i)\n",
    "        submit.click()\n",
    "        try:\n",
    "            link = driver.find_element(By.XPATH,\"//a[@class='ipc-metadata-list-summary-item__t']\").get_attribute('href')\n",
    "            driver.get(link)\n",
    "            link = link.split('?')\n",
    "            link = link[0]\n",
    "            #print(link)\n",
    "            x = extract(link)\n",
    "            #print(x)\n",
    "            link+='keywords/'\n",
    "            driver.get(link)\n",
    "            data = driver.find_element(By.XPATH,\"//section[@class='ipc-page-section ipc-page-section--base']\")\n",
    "            k_h = {}\n",
    "            k = data.find_elements(By.XPATH,\"//a[@class='ipc-metadata-list-summary-item__t']\")\n",
    "            h = data.find_elements(By.XPATH,\"//span[@class='ipc-voting__label__count ipc-voting__label__count--up']\")\n",
    "            for i in range(len(k)):\n",
    "                k_h[k[i].text] = h[i].text\n",
    "            x['keywords'] = k_h\n",
    "            print(x)\n",
    "            load(x)\n",
    "            driver.quit()\n",
    "        except:\n",
    "            driver.quit()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
